---
title: "Introduction to samplyr"
output: rmarkdown::html_vignette
bibliography: references.bib
link-citations: true
vignette: >
  %\VignetteIndexEntry{Introduction to samplyr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message = FALSE, echo = FALSE}
library(samplyr)
library(dplyr)
```

## Overview

`samplyr` provides a tidy grammar for specifying and executing survey sampling designs. The package is built around a minimal set of composable verbs that handle stratified, clustered, and multi-stage sampling.

For the statistical semantics and assumptions underlying each operation, see `vignette("design-semantics")`.

The core idea is that sampling code should read like its English description:

```{r, eval = FALSE}
library(samplyr)
library(dplyr)

# "Stratify by region, proportionally allocate 500 samples, execute"
sampling_design(title = "My sampling design") |>
  stratify_by(region, alloc = "proportional") |>
  draw(n = 500) |>
  execute(frame, seed = 1)
```

To see how this works in practice, consider a real survey design from @lohr2022 (Example 7.1), based on a 1991 study of bed net use in rural Gambia (D'Alessandro et al., 1994):

> Malaria morbidity can be reduced by using bed nets impregnated with insecticide, but this is only effective if the bed nets are in widespread use. In 1991, a nationwide survey was designed to estimate the prevalence of bed net use in rural areas of the Gambia (D'Alessandro et al., 1994).
>
> The sampling frame consisted of all rural villages of fewer than 3,000 people. The villages were **stratified by three geographic regions** (eastern, central, and western) and by **whether the village had a public health clinic (PHC)** or not. In each region **five districts were chosen with probability proportional to the district population**. In each district **four villages were chosen, again with probability proportional to census population**: two PHC villages and two non-PHC villages. Finally, **six compounds were chosen** more or less randomly from each village.

In samplyr, this three-stage stratified cluster design translates directly into code:


```{r}
design <- sampling_design(title = "Gambia bed net") |>
  add_stage() |>
    stratify_by(region) |>
    cluster_by(district) |>
    draw(n = 5, method = "pps_brewer", mos = population) |>
  add_stage() |>
    stratify_by(phc) |>
    cluster_by(village) |>
    draw(n = 2, method = "pps_brewer", mos = population) |>
  add_stage() |>
  draw(n = 6)
design
```

And you

```{r, eval = FALSE}
sampling_design(title = "Gambia bed net") |>
  add_stage() |>
    stratify_by(region) |>
    cluster_by(district) |>
    draw(n = 5, method = "pps_brewer", mos = population) |>
  add_stage() |>
    stratify_by(phc) |>
    cluster_by(village) |>
    draw(n = 2, method = "pps_brewer", mos = population) |>
  add_stage() |>
    draw(n = 6) |>
  execute(frame, seed = 1991)

# or
execute(design, frame, seed = 1991)
```

The samplyr code mirrors the verbal description verb for verb.

## The Grammar

`samplyr` uses 5 verbs and 1 modifier:

| Function | Purpose |
|----------|---------|
| `sampling_design()` | Create a new sampling design |
| `stratify_by()` | Define stratification variables and allocation |
| `cluster_by()` | Define cluster/PSU variable |
| `draw()` | Specify sample size, method, and measure of size |
| `execute()` | Run the design on a frame |
| `add_stage()` | Delimit stages in multi-stage designs |

## Deferred Column Resolution

`stratify_by()` and `cluster_by()` accept bare column names and store
them in the design object. Column names are validated only when
a frame is available (`execute()`, `as_svydesign()`), which
keeps design specification separate from execution.

```{r, eval = FALSE}
design <- sampling_design(title = "Stratified cluster sampling") |>
  stratify_by(region, alloc = "proportional") |>
  cluster_by(ea_id) |>
  draw(n = 200)

sample <- execute(design, bfa_eas, seed = 101)
```

## Example Data

We'll use the `bfa_eas` dataset throughout this vignette. It is an enumeration area frame for Burkina Faso, with ~14,900 EAs across 13 regions.

```{r}
data(bfa_eas)

bfa_eas |>
  glimpse()
```

---

## Simple Random Sampling

The most basic design selects n units at random from the frame.

```{r}
design <- sampling_design(title = "Simple Random Sampling") |>
  draw(n = 100)
design
```

The `sampling_design` object stores design metadata and can be reused.

```{r}
sample <- execute(design, bfa_eas, seed = 24)
nrow(sample)
```


The result includes the original columns plus sampling metadata: `.weight` (sampling weight), `.weight_1`, `.weight_2`, etc. (per-stage weights). For with-replacement methods, `.draw_1`, `.draw_2`, etc. each independent draw.

```{r}
sample |>
  select(ea_id, region, urban_rural, .weight, .weight_1) |>
  head()
```

### Selection Methods

The `method` argument controls how units are selected. By default, `samplyr` uses simple random sampling without replacement (`srswor`).

Systematic sampling selects units at fixed intervals, which can improve precision when the frame is ordered.

```{r}
sample_sys <- sampling_design(title = "Systematic") |>
  draw(n = 100, method = "systematic") |>
  execute(bfa_eas, seed = 2021)
head(sample_sys)
```

Sampling with replacement allows the same unit to be selected multiple times, useful for bootstrap procedures.

```{r}
sample_wr <- sampling_design(title = "SRS WR") |>
  draw(n = 100, method = "srswr") |>
  execute(bfa_eas, seed = 123)
head(sample_wr)
```

### Using Sampling Fractions

Instead of a fixed sample size, you can specify a sampling fraction with `frac`.

```{r}
sample <- sampling_design() |>
  draw(frac = 0.05) |>
  execute(bfa_eas, seed = 1789)
nrow(sample)
```

Bernoulli sampling selects each unit independently with the specified probability. This gives a random sample size, which can simplify field protocols.

```{r}
sample <- sampling_design() |>
  draw(frac = 0.05, method = "bernoulli") |>
  execute(bfa_eas, seed = 1960)
nrow(sample)
```

### Rounding Behavior

When using `frac`, the computed sample size (N × frac) must be rounded to an integer. By default, `samplyr` rounds up (ceiling), which matches SAS SURVEYSELECT's default behavior. Use the `round` argument to control this:

- `"up"` (default): round up, ensures adequate sample size
- `"down"`: round down, minimum sample size
- `"nearest"`: Standard mathematical rounding

```{r}
# Frame of 105 units, frac = 0.1 → 10.5
frame_105 <- head(bfa_eas, 105)

# Default: rounds up to 11
nrow(sampling_design() |> draw(frac = 0.1) |> execute(frame_105, seed = 3))

# Round down to 10
nrow(sampling_design() |> draw(frac = 0.1, round = "down") |> execute(frame_105, seed = 3))

# Round to nearest (10)
nrow(sampling_design() |> draw(frac = 0.1, round = "nearest") |> execute(frame_105, seed = 3))
```

---

## Stratified Sampling

Stratification partitions the frame into non-overlapping groups (strata) and samples from each. This ensures representation from all subgroups and often improves precision.

### Per-Stratum Sample Size

Without an allocation method, `n` specifies the sample size within each stratum.

```{r}
sample <- sampling_design() |>
  stratify_by(region) |>
  draw(n = 20) |>
  execute(bfa_eas, seed = 123)

sample |>
  count(region)
```

### Allocation Methods

With an allocation method, `n` becomes the total sample size to distribute across strata. Allocation methods are defined for total sample-size allocation, so `draw(frac = ...)` is not supported when `alloc` is set.

**Proportional allocation** distributes the sample proportionally to stratum sizes, ensuring the sample mirrors the population structure.

```{r}
sample <- sampling_design(title = "Proportional Allocation") |>
  stratify_by(region, alloc = "proportional") |>
  draw(n = 300) |>
  execute(bfa_eas, seed = 42)

sample |>
  count(region) |>
  mutate(pct = n / sum(n))
```

**Equal allocation** assigns the same sample size to each stratum, regardless of population size. This maximizes precision for comparisons between strata.

```{r}
sample <- sampling_design(title = "Equal Allocation") |>
  stratify_by(region, alloc = "equal") |>
  draw(n = 160) |>
  execute(bfa_eas, seed = 2026)

sample |>
  count(region)
```

**Neyman allocation** minimizes the variance of the overall estimate by allocating more sample to strata with higher variability. It requires prior information about stratum variances.
Use explicit stratification variable names when passing `variance`.

```{r}
data(bfa_eas_variance)

bfa_eas_variance

sample <- sampling_design(title = "Neyman Allocation") |>
  stratify_by(region, alloc = "neyman", variance = bfa_eas_variance) |>
  draw(n = 300) |>
  execute(bfa_eas, seed = 12345)

sample |>
  count(region)
```

**Optimal allocation** extends Neyman allocation by also accounting for differential costs across strata. It minimizes variance for a fixed budget (or cost for fixed precision).
Use explicit stratification variable names when passing `variance`/`cost`.

```{r}
data(bfa_eas_cost)

bfa_eas_cost

sample <- sampling_design(title = "Optimal Allocation") |>
  stratify_by(region, alloc = "optimal",
              variance = bfa_eas_variance,
              cost = bfa_eas_cost) |>
  draw(n = 300) |>
  execute(bfa_eas, seed = 9876)

sample |>
  count(region)
```

**Power allocation** [@bankier1988] uses \(n_h \propto C_h X_h^q\), where `cv` supplies \(C_h\), `importance` supplies \(X_h\), and `power` is \(q \in [0, 1]\).

```{r}
cv_df <- data.frame(
  region = levels(bfa_eas$region),
  cv = c(0.40, 0.35, 0.12, 0.20, 0.30, 0.18,
         0.15, 0.38, 0.22, 0.32, 0.17, 0.45, 0.25)
)

importance_df <- data.frame(
  region = levels(bfa_eas$region),
  importance = c(60, 40, 120, 70, 80, 65,
                 50, 55, 90, 75, 45, 35, 30)
)

sample <- sampling_design(title = "Power Allocation") |>
  stratify_by(
    region,
    alloc = "power",
    cv = cv_df,
    importance = importance_df,
    power = 0.5
  ) |>
  draw(n = 300) |>
  execute(bfa_eas, seed = 777)

sample |>
  count(region)
```

### Sample Size Bounds

When using allocation methods, you can constrain stratum sample sizes with `min_n` and `max_n` in `draw()`.

**Minimum sample size** ensures every stratum gets at least the specified number of units. This is essential for variance estimation (requires n ≥ 2 per stratum) or when you need reliable subgroup estimates.

```{r}
# Neyman allocation with minimum 5 per stratum
sample <- sampling_design() |>
  stratify_by(region, alloc = "neyman", variance = bfa_eas_variance) |>
  draw(n = 300, min_n = 20) |>
  execute(bfa_eas, seed = 1)

sample |>
  count(region)
```

**Maximum sample size** caps large strata to prevent them from dominating the sample. This is useful when operational constraints limit how many units you can handle in any one stratum.

```{r}
# Proportional allocation but cap at 60 per stratum
sample <- sampling_design() |>
  stratify_by(region, alloc = "proportional") |>
  draw(n = 300, max_n = 55) |>
  execute(bfa_eas, seed = 40)

sample |>
  count(region)
```

**Both bounds together** create a feasible range for each stratum:

```{r}
sample <- sampling_design() |>
  stratify_by(region, alloc = "proportional") |>
  draw(n = 300, min_n = 20, max_n = 55) |>
  execute(bfa_eas, seed = 2003)

sample |>
  count(region)
```

When a stratum's population is smaller than `min_n`, the entire stratum is selected (capped at population size).

**Custom allocation** lets you specify exact sample sizes or rates per stratum by passing a data frame to `draw()`.

```{r}
sizes_df <- data.frame(
  region = levels(bfa_eas$region),
  n = c(20, 12, 25, 18, 22, 16, 14, 15, 20, 18, 12, 10, 8)
)

sample <- sampling_design() |>
  stratify_by(region) |>
  draw(n = sizes_df) |>
  execute(bfa_eas, seed = 101)

sample |>
  count(region)
```

### Multiple Stratification Variables

You can stratify by multiple variables to create crossed strata. Here we stratify by both region and urban/rural status.

```{r}
sample <- sampling_design() |>
  stratify_by(region, urban_rural, alloc = "proportional") |>
  draw(n = 300) |>
  execute(bfa_eas, seed = 42)

sample |>
  count(region, urban_rural) |>
  head(10)
```

---

## Cluster Sampling

Cluster sampling selects groups (clusters) rather than individual units. This is practical when a complete list of individuals isn't available or when travel costs make dispersed sampling expensive.

Use `cluster_by()` to specify the cluster identifier. All units within selected clusters are included.

```{r}
sample <- sampling_design() |>
  cluster_by(ea_id) |>
  draw(n = 50) |>
  execute(bfa_eas, seed = 120)

sample |>
  summarise(
    n_clusters = n_distinct(ea_id),
    n_units = n()
  )
```

---

## PPS Sampling

Probability Proportional to Size (PPS) sampling selects units with probability proportional to a size measure. This is standard for cluster sampling where clusters vary in size.

Use the `mos` argument to specify the measure of size variable. Here we select EAs with probability proportional to their household count.

```{r}
sample_pps <- sampling_design() |>
  cluster_by(ea_id) |>
  draw(n = 50, method = "pps_brewer", mos = households) |>
  execute(bfa_eas, seed = 365)

sample_pps |>
  summarise(
    mean_hh = mean(households),
    median_hh = median(households)
  )
```

Compared to simple random sampling, PPS tends to select larger clusters:

```{r}
sample_srs <- sampling_design() |>
  cluster_by(ea_id) |>
  draw(n = 50) |>
  execute(bfa_eas, seed = 42)

bind_rows(
  sample_pps |> summarise(method = "PPS", mean_hh = mean(households)),
  sample_srs |> summarise(method = "SRS", mean_hh = mean(households))
)
```

### PPS Methods

`samplyr` supports several PPS methods:

| Method            | Description                                                           |
|-------------------|-----------------------------------------------------------------------|
| `pps_brewer`      | Brewer's method - fast with good properties (recommended)             |
| `pps_systematic`  | PPS systematic - simple but can have periodicity issues               |
| `pps_cps`         | Conditional Poisson sampling (maximum entropy)                        |
| `pps_poisson`     | PPS Poisson - random sample size (requires `frac` and supports `prn`) |
| `pps_sps`         | Sequential Poisson sampling (supports `prn`)                          |
| `pps_pareto`      | Pareto sampling (supports `prn`)                                      |
| `pps_multinomial` | PPS with replacement                                                  |
| `pps_chromy`      | Chromy's sequential PPS / minimum replacement                         |

### Certainty Selection

In PPS sampling, very large units can have expected inclusion probabilities above 1. Certainty selection handles this by selecting those units with probability 1 and sampling the rest normally.

Use `certainty_size` for an absolute threshold or `certainty_prop` for a proportional one.

```{r}
sample_cert <- sampling_design(title = "Certainty selection") |>
  draw(n = 50, method = "pps_brewer", mos = households,
       certainty_size = 800) |>
  execute(bfa_eas, seed = 123)

# How many EAs with more than 800 households
filter(bfa_eas, households > 800)

# Check which units were selected with certainty
count(sample_cert, .certainty_1)
```

With `certainty_prop`, units whose MOS proportion exceeds the threshold are taken with certainty. The process is iterative: after removing certainty units, proportions are recomputed.

```{r}
sample_certp <- sampling_design() |>
  stratify_by(region) |>
  draw(n = 50, method = "pps_systematic", mos = households,
       certainty_prop = 0.05) |>
  execute(bfa_eas, seed = 12345)

# How many EAs with more than 5% of the total hh by region
bfa_eas |>
  mutate(mosprop = households/sum(households),
         .by = region) |>
  filter(mosprop >= 0.05)

filter(sample_certp, .certainty_1)
```

### Permanent Random Numbers (PRN)

Some PPS methods support permanent random numbers for sample coordination across survey waves. Assign a stable U(0,1) value to each frame unit, then pass it via `prn`:

```{r}
set.seed(1)
bfa_eas$prn <- runif(nrow(bfa_eas))

sample_prn <- sampling_design(title = "Samples coordination with PRN") |>
  cluster_by(ea_id) |>
  draw(n = 50, method = "pps_sps", mos = households, prn = prn) |>
  execute(bfa_eas, seed = 1)
sample_prn
```

Because the PRN values are stable, re-executing the same design on the same frame produces highly overlapping samples (positive coordination). PRN is supported for `bernoulli`, `pps_poisson`, `pps_sps`, and `pps_pareto`. You can learn more about coordination with permanent random numbers in the following vignette `vignette("sampling-coordination")`.

---

## Control Sorting and Serpentine Ordering

Control sorting orders the frame before selection, providing implicit stratification. This is effective with systematic and sequential methods, where it ensures the sample spreads evenly across the sorted variables.

```{r}
# Nested sorting: standard ascending order
sample_sort <- sampling_design() |>
  draw(n = 100, method = "systematic",
       control = c(region, province)) |>
  execute(bfa_eas, seed = 98765)
head(sample_sort)
```

`serp()` implements serpentine (snake) sorting, which alternates direction at each level of the hierarchy. This minimizes jumps at boundaries, matching SAS PROC SURVEYSELECT's `SORT=SERP`.

```{r}
# Serpentine sorting
sample_serp <- sampling_design() |>
  draw(n = 100, method = "systematic",
       control = serp(region, province)) |>
  execute(bfa_eas, seed = 1)
head(sample_serp)
```

Control sorting can be combined with explicit stratification. The sorting is then applied within each stratum.

```{r}
sample_serp2 <- sampling_design() |>
  stratify_by(urban_rural) |>
  draw(n = 100, method = "systematic",
       control = serp(region, province)) |>
  execute(bfa_eas, seed = 2)
head(sample_serp2)
```

---

## Balanced Sampling

Balanced sampling selects a sample whose Horvitz-Thompson estimates of auxiliary totals match (or nearly match) the population totals. This improves precision for any variable correlated with the auxiliary variables. samplyr implements the cube method (Deville & Tille 2004) via `method = "balanced"`.

Specify auxiliary variables with `aux`. Without `mos`, inclusion probabilities are equal; with `mos`, they are proportional to size:

```{r}
# Equal-probability balanced sample
balanced_eq <- sampling_design() |>
  draw(n = 100, method = "balanced",
       aux = c(population, households)) |>
  execute(bfa_eas, seed = 42)
balanced_eq
```

The balancing property means the HT estimate of auxiliary totals is close to the true total:

```{r}
pop_total <- sum(bfa_eas$population)
ht_total <- sum(balanced_eq$population * balanced_eq$.weight)
c(population = pop_total, ht_estimate = ht_total)
```

Balanced sampling combines naturally with stratification. When stratified, samplyr calls the stratified cube algorithm (Chauvet 2009) in a single pass, preserving the allocation computed by `stratify_by()`:

```{r}
# Stratified PPS balanced sample
balanced_strat <- sampling_design() |>
  stratify_by(region, alloc = "proportional") |>
  draw(n = 300, method = "balanced", mos = households,
       aux = c(population, area_km2)) |>
  execute(bfa_eas, seed = 1960)
balanced_strat
```

When used with `cluster_by()`, auxiliary values are automatically aggregated (summed) to the cluster level before selection.

Balanced sampling supports up to 2 stages. At stage 1, element-level auxiliary variables are aggregated to PSU totals; at stage 2, the cube method runs on the element-level frame within each selected PSU.

---

## Multi-Stage Sampling

Multi-stage designs sample in stages: first select primary sampling units (PSUs), then sample within them. This is the standard approach for large-scale surveys when a complete frame of ultimate units isn't available upfront.

Use `add_stage()` to delimit each stage of the design.

### Two-Stage Design

For this example, we'll use `zwe_eas` to demonstrate a two-stage design: first select districts as PSUs, then sample EAs within selected districts.

```{r}
data(zwe_eas)

# First, let's see the structure: EAs nested within districts
zwe_eas |>
  count(province, district) |>
  head(10)
```

We need to create a measure of size for districts. Here we'll use total households per district.

```{r}
# Add district-level households as MOS
zwe_frame <- zwe_eas |>
  mutate(district_hh = sum(households),
         .by = district)
```

Now we can run a two-stage design: select 10 districts with PPS, then sample 5 EAs within each.

```{r}
twostage_design <- sampling_design(title = "Two-stage cluster sampling") |>
  add_stage(label = "Districts") |>
    cluster_by(district) |>
    draw(n = 10, method = "pps_brewer", mos = district_hh) |>
  add_stage(label = "EAs") |>
  draw(n = 5)
twostage_design
```

Let's apply it to the frame.

```{r}
sample_eas <- execute(twostage_design,
                      zwe_frame, seed = 3)

sample_eas |>
  summarise(n_districts = n_distinct(district),
            n_eas = n())
```

### Stratified Multi-Stage Design

Combining stratification with multi-stage sampling is standard for national surveys. Here we stratify by province (which is constant within districts), then select districts and EAs within each stratum.

```{r}
sample_eas2 <- sampling_design(title = "Stratified two-stage cluster sampling") |>
  add_stage(label = "Districts") |>
    stratify_by(province) |>
    cluster_by(district) |>
    draw(n = 2, method = "pps_brewer", mos = district_hh) |>
  add_stage(label = "EAs") |>
    draw(n = 3) |>
  execute(zwe_frame, seed = 4)

sample_eas2 |>
  count(province, district)
```

---

## Operational Multi-Stage Sampling

In practice, multi-stage surveys often execute stages at different times. After selecting PSUs, field teams may need to conduct listing or other operations before the second stage can proceed.

The `stages` argument lets you execute only specific stages.

```{r}
design <- sampling_design() |>
  add_stage(label = "Districts") |>
    stratify_by(province) |>
    cluster_by(district) |>
    draw(n = 2, method = "pps_brewer", mos = district_hh) |>
  add_stage(label = "EAs") |>
    draw(n = 4)

# Execute stage 1 only
selected_districts <- execute(design, zwe_frame, stages = 1, seed = 42)

selected_districts |>
  distinct(province, district)
```

After fieldwork or preparation is complete, execute the remaining stages.

```{r}
final_sample <- selected_districts |>
  execute(zwe_frame, seed = 43)

final_sample |>
  count(province, district)
```

---

## Working with Results

### Accessing the Design

The sampling design is attached to the result and can be retrieved with `get_design()`.

```{r}
sample <- sampling_design() |>
  stratify_by(region, alloc = "proportional") |>
  draw(n = 200) |>
  execute(bfa_eas, seed = 2024)

design <- get_design(sample)
design
```

and accessing element of the design

```{r}
design$stages[[1]]$strata$vars
```

### Weight Diagnostics

The `summary()` method reports weight diagnostics including Kish's effective sample size and design effect due to unequal weighting. For the full design
effect (including clustering and stratification), use `survey::svymean()` with `deff = TRUE` after converting with `as_svydesign()`.

```{r}
summary(sample)
```

---

## Method Reference

### Selection Methods

| Method            | Sample Size | Replacement                                                    | Notes                                        |
|-------------------|-------------|----------------------------------------------------------------|----------------------------------------------|
| `srswor`          | Fixed       | No                                                             | Default, general purpose                     |
| `srswr`           | Fixed       | Yes                                                            | Bootstrap, rare populations                  |
| `systematic`      | Fixed       | No                                                             | Ordered frames                               |
| `bernoulli`       | Random      | No                                                             | Simple field protocols                       |
| `pps_brewer`      | Fixed       | No                                                             | Recommended PPS method                       |
| `pps_systematic`  | Fixed       | No                                                             | Simple PPS                                   |
| `pps_cps`         | Fixed       | No                                                             | Maximum entropy, exact joint inclusion probs |
| `pps_poisson`     | Random      | No                                                             | PPS with random size                         |
| `pps_sps`         | Fixed       | No                                                             | Sequential Poisson, supports PRN             |
| `pps_pareto`      | Fixed       | No                                                             | Pareto sampling, supports PRN                |
| `pps_multinomial` | Fixed       | Yes                                                            | PPS with replacement                         |
| `pps_chromy`      | Fixed       | PMR.^[Probability Minimum Replacement based on expected hits.] | Chromy's sequential PPS                      |
| `balanced`        | Fixed       | No                                                             | Cube method, balances on `aux` variables     |

### Allocation Methods

| Method         | Description                           | Requirements                             |
|----------------|---------------------------------------|------------------------------------------|
| (none)         | n per stratum                         |                                          |
| `equal`        | Same n per stratum                    |                                          |
| `proportional` | n ∝ stratum size                      |                                          |
| `neyman`       | Minimize variance                     | `variance` data frame                    |
| `optimal`      | Minimize variance/cost                | `variance` + `cost` data frames          |
| `power`        | Compromise: \(n_h \propto C_h X_h^q\) | `cv` + `importance` (+ optional `power`) |

For custom stratum-specific sizes or rates, pass a data frame directly to `n` or `frac` in `draw()`.
When `alloc` is specified, use `n` (not `frac`).

### Sample Size Bounds

| Argument | Description                                                        |
|----------|--------------------------------------------------------------------|
| `min_n`  | Minimum sample size per stratum (for variance estimation, set ≥ 2) |
| `max_n`  | Maximum sample size per stratum (to cap dominant strata)           |

These only apply when using allocation methods (`equal`, `proportional`, `neyman`, `optimal`, `power`).

### Rounding Methods

| Value       | Description                              |
|-------------|------------------------------------------|
| `"up"`      | Round up (ceiling), default, matches SAS |
| `"down"`    | Round down (floor)                       |
| `"nearest"` | Standard mathematical rounding           |

These apply when using `frac` to specify sampling rates. When computed sample size < 1, it is always rounded up to 1.

---

## Best Practices

1. **Always set a seed** for reproducibility
2. **Use meaningful stage labels** for documentation
3. **Validate designs** with `validate_frame()` before execution
4. **Check weight distributions** with `summary()` on the sample

```{r}
design <- sampling_design(title = "National Health Survey 2024") |>
  add_stage(label = "Enumeration Areas") |>
    stratify_by(region, urban_rural) |>
    cluster_by(ea_id) |>
    draw(n = 5, method = "pps_brewer", mos = households) |>
  add_stage(label = "Households") |>
    draw(n = 20)

print(design)
```

### Frame Validation

Use `validate_frame()` to check that a frame has all the variables a design requires before executing.

```{r, error = TRUE}
# This passes
validate_frame(design, bfa_eas)

# This fails with a clear message
bad_frame <- data.frame(id = 1:100, value = rnorm(100))
validate_frame(design, bad_frame)
```

## Reference
